{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsF8yRafNKjw"
      },
      "source": [
        "This notebook trains a binary classifier on a dataset which contains movie reviews which are labelled as containing either *positive* or *negative* sentiment towards the movie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzUZxeMbRPoM"
      },
      "source": [
        "First we will install *sklearn* which we will be using to do the machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV8dcUsoOA_l",
        "outputId": "29f63dc9-908d-4cc1-9f83-a04cd179bf34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekmP1Ry1R00y"
      },
      "source": [
        "Next we will install the dataset. We will use the IMDB sentiment analysis dataset available from the [huggingface datasets library](https://huggingface.co/datasets/imdb) and described in [Maas et al. 2011](https://aclanthology.org/P11-1015.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd0bLG6nOE4D",
        "outputId": "8a0cff2a-7c8c-4413-fac9-9b7cc7f6804d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h6B6dXHSP6X"
      },
      "source": [
        "Now let's load the IMDB training set. We will print out the last instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOO5rQFHUg8D",
        "outputId": "19171d0b-bb6a-49d4-b240-a249c5cd664a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.', 'label': 1}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "imdb_dataset = load_dataset(\"imdb\")['train']\n",
        "print(imdb_dataset[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enwDYpN7Hwgw"
      },
      "source": [
        "Let's convert the training data into the format expected by scikit-learn - a list of input vectors (documents) and a list of associated output labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8xfDeEMWq1o",
        "outputId": "9b9b97c8-a9d7-4cd3-c4d5-ca4a08c11d53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "train_data = []\n",
        "train_data_labels = []\n",
        "for item in imdb_dataset:\n",
        "  train_data.append(item['text'])\n",
        "  train_data_labels.append(item['label'])\n",
        "print(train_data[-1])\n",
        "print(train_data_labels[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI6ab7wOIOu2"
      },
      "source": [
        "We'll use the CountVectorizer class to extract the words in each review as the features the algorithm will learn from. Each document is represented as a 1000 dimension vector of word  counts. Counts > 1 are clipped to 1. Stop words are removed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vDYo_rZkXZUZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(analyzer='word',max_features=1000,lowercase=True,binary=True,stop_words='english')\n",
        "features = vectorizer.fit_transform(train_data).toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7l9Xg1TTfkV"
      },
      "source": [
        "As a sanity check, let's check we have a 2-d array where each row is one of the 25,000 instances and each column is one of 16000 words or word bigrams. Print out the ngrams that will be used for classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oW0zYH0TdPm",
        "outputId": "c063fa4b-8cd5-490e-e0f9-7eb34375ade9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 1000)\n",
            "['10' '100' '15' '20' '30' '50' '80' '90' 'ability' 'able' 'absolutely'\n",
            " 'accent' 'act' 'acted' 'acting' 'action' 'actor' 'actors' 'actress'\n",
            " 'actual' 'actually' 'add' 'added' 'admit' 'adult' 'adventure' 'age' 'ago'\n",
            " 'agree' 'air' 'alive' 'amazing' 'america' 'american' 'amusing'\n",
            " 'animation' 'annoying' 'anti' 'apart' 'apparently' 'appeal' 'appear'\n",
            " 'appearance' 'appears' 'appreciate' 'aren' 'art' 'aside' 'ask' 'aspect'\n",
            " 'atmosphere' 'attempt' 'attempts' 'attention' 'audience' 'audiences'\n",
            " 'average' 'avoid' 'away' 'awesome' 'awful' 'baby' 'background' 'bad'\n",
            " 'badly' 'barely' 'based' 'basic' 'basically' 'battle' 'beautiful'\n",
            " 'beautifully' 'beauty' 'begin' 'beginning' 'begins' 'believable'\n",
            " 'believe' 'best' 'better' 'big' 'biggest' 'bit' 'bizarre' 'black' 'blood'\n",
            " 'body' 'book' 'books' 'bored' 'boring' 'bought' 'box' 'boy' 'boys' 'br'\n",
            " 'brain' 'break' 'brilliant' 'bring' 'brings' 'british' 'brother'\n",
            " 'brothers' 'brought' 'budget' 'bunch' 'business' 'buy' 'called' 'came'\n",
            " 'camera' 'car' 'care' 'career' 'case' 'cast' 'casting' 'catch' 'caught'\n",
            " 'cause' 'century' 'certain' 'certainly' 'chance' 'change' 'changed'\n",
            " 'character' 'characters' 'charming' 'cheap' 'check' 'cheesy' 'chemistry'\n",
            " 'child' 'children' 'choice' 'cinema' 'cinematography' 'city' 'class'\n",
            " 'classic' 'clear' 'clearly' 'clever' 'climax' 'close' 'cold' 'college'\n",
            " 'come' 'comedy' 'comes' 'comic' 'coming' 'comment' 'comments' 'common'\n",
            " 'company' 'compared' 'complete' 'completely' 'concept' 'conclusion'\n",
            " 'consider' 'considered' 'considering' 'control' 'convincing' 'cool' 'cop'\n",
            " 'copy' 'couldn' 'country' 'couple' 'course' 'cover' 'crap' 'crazy'\n",
            " 'create' 'created' 'credit' 'credits' 'creepy' 'crew' 'crime' 'cult'\n",
            " 'culture' 'cut' 'cute' 'dance' 'dancing' 'dark' 'date' 'daughter' 'david'\n",
            " 'day' 'days' 'dead' 'deal' 'death' 'decent' 'decide' 'decided' 'decides'\n",
            " 'deep' 'definitely' 'depth' 'deserves' 'despite' 'development' 'dialog'\n",
            " 'dialogue' 'did' 'didn' 'die' 'died' 'different' 'difficult' 'directed'\n",
            " 'directing' 'direction' 'director' 'directors' 'disappointed' 'disney'\n",
            " 'disturbing' 'doctor' 'documentary' 'does' 'doesn' 'dog' 'doing' 'don'\n",
            " 'doubt' 'dr' 'drama' 'dramatic' 'drawn' 'dream' 'drive' 'dull' 'dumb'\n",
            " 'dvd' 'earlier' 'early' 'earth' 'easily' 'easy' 'edge' 'editing' 'effect'\n",
            " 'effective' 'effects' 'effort' 'elements' 'emotional' 'end' 'ended'\n",
            " 'ending' 'ends' 'english' 'enjoy' 'enjoyable' 'enjoyed' 'entertaining'\n",
            " 'entertainment' 'entire' 'entirely' 'episode' 'episodes' 'equally' 'era'\n",
            " 'escape' 'especially' 'events' 'eventually' 'evil' 'ex' 'exactly'\n",
            " 'example' 'excellent' 'exciting' 'excuse' 'expect' 'expected' 'expecting'\n",
            " 'experience' 'explain' 'extremely' 'eye' 'eyes' 'face' 'fact' 'failed'\n",
            " 'fails' 'fair' 'fairly' 'fake' 'fall' 'falls' 'familiar' 'family'\n",
            " 'famous' 'fan' 'fans' 'fantastic' 'fantasy' 'far' 'fast' 'father'\n",
            " 'favorite' 'fear' 'feature' 'features' 'feel' 'feeling' 'feels' 'felt'\n",
            " 'female' 'fi' 'fight' 'fighting' 'figure' 'filled' 'film' 'filmed'\n",
            " 'filmmakers' 'films' 'final' 'finally' 'finds' 'fine' 'fit' 'flat'\n",
            " 'flick' 'focus' 'follow' 'following' 'follows' 'footage' 'force' 'forced'\n",
            " 'forget' 'form' 'forward' 'free' 'french' 'friend' 'friends' 'fully'\n",
            " 'fun' 'funny' 'future' 'game' 'garbage' 'gave' 'general' 'generally'\n",
            " 'genius' 'genre' 'george' 'gets' 'getting' 'girl' 'girlfriend' 'girls'\n",
            " 'given' 'gives' 'giving' 'glad' 'god' 'goes' 'going' 'gone' 'good' 'gore'\n",
            " 'got' 'grade' 'great' 'greatest' 'group' 'guess' 'gun' 'guy' 'guys'\n",
            " 'hair' 'half' 'hand' 'hands' 'happen' 'happened' 'happens' 'happy' 'hard'\n",
            " 'hardly' 'hate' 'haven' 'having' 'head' 'hear' 'heard' 'heart' 'heavy'\n",
            " 'hell' 'help' 'hero' 'high' 'highly' 'hilarious' 'history' 'hit' 'hold'\n",
            " 'hollywood' 'home' 'honest' 'honestly' 'hope' 'horrible' 'horror' 'hot'\n",
            " 'hour' 'hours' 'house' 'huge' 'human' 'humor' 'husband' 'idea' 'ideas'\n",
            " 'images' 'imagine' 'imdb' 'immediately' 'important' 'impossible'\n",
            " 'impressive' 'including' 'incredible' 'incredibly' 'inside' 'instead'\n",
            " 'intelligent' 'interested' 'interesting' 'involved' 'involving' 'isn'\n",
            " 'jack' 'james' 'japanese' 'job' 'joe' 'john' 'joke' 'jokes' 'just'\n",
            " 'keeps' 'kept' 'kid' 'kids' 'kill' 'killed' 'killer' 'killing' 'kills'\n",
            " 'kind' 'king' 'knew' 'know' 'knowing' 'known' 'knows' 'lack' 'lady'\n",
            " 'lame' 'language' 'large' 'late' 'later' 'laugh' 'laughable' 'laughing'\n",
            " 'laughs' 'law' 'lead' 'leading' 'leads' 'learn' 'leave' 'leaves'\n",
            " 'leaving' 'lee' 'left' 'let' 'level' 'life' 'light' 'like' 'liked'\n",
            " 'likely' 'likes' 'line' 'lines' 'list' 'literally' 'little' 'live'\n",
            " 'lives' 'living' 'll' 'local' 'long' 'longer' 'look' 'looked' 'looking'\n",
            " 'looks' 'lost' 'lot' 'lots' 'loud' 'love' 'loved' 'low' 'mad' 'main'\n",
            " 'major' 'make' 'makers' 'makes' 'making' 'male' 'man' 'managed' 'manages'\n",
            " 'mark' 'married' 'masterpiece' 'material' 'matter' 'maybe' 'mean'\n",
            " 'meaning' 'means' 'meant' 'meet' 'meets' 'members' 'memorable' 'men'\n",
            " 'mention' 'mentioned' 'mess' 'message' 'michael' 'middle' 'mind' 'minute'\n",
            " 'minutes' 'miss' 'missed' 'missing' 'mistake' 'modern' 'moment' 'moments'\n",
            " 'money' 'monster' 'mood' 'mother' 'motion' 'moves' 'movie' 'movies'\n",
            " 'moving' 'mr' 'murder' 'music' 'musical' 'mystery' 'named' 'natural'\n",
            " 'nature' 'near' 'nearly' 'need' 'needed' 'needs' 'new' 'nice' 'night'\n",
            " 'non' 'normal' 'note' 'novel' 'nudity' 'number' 'obvious' 'obviously'\n",
            " 'odd' 'office' 'oh' 'ok' 'okay' 'old' 'older' 'ones' 'open' 'opening'\n",
            " 'opinion' 'order' 'original' 'oscar' 'outside' 'outstanding' 'overall'\n",
            " 'pace' 'parents' 'particular' 'particularly' 'parts' 'party' 'pass'\n",
            " 'past' 'pathetic' 'paul' 'pay' 'people' 'perfect' 'perfectly'\n",
            " 'performance' 'performances' 'period' 'person' 'personal' 'personally'\n",
            " 'peter' 'pick' 'picture' 'pictures' 'piece' 'place' 'plain' 'play'\n",
            " 'played' 'playing' 'plays' 'plenty' 'plot' 'plus' 'point' 'pointless'\n",
            " 'points' 'police' 'political' 'poor' 'poorly' 'popular' 'portrayal'\n",
            " 'portrayed' 'positive' 'possible' 'possibly' 'post' 'potential' 'power'\n",
            " 'powerful' 'predictable' 'premise' 'present' 'pretty' 'previous'\n",
            " 'probably' 'problem' 'problems' 'produced' 'producers' 'production'\n",
            " 'project' 'public' 'pure' 'purpose' 'quality' 'question' 'questions'\n",
            " 'quickly' 'quite' 'rare' 'rate' 'rated' 'rating' 'read' 'reading' 'real'\n",
            " 'realistic' 'reality' 'realize' 'really' 'reason' 'reasons' 'recent'\n",
            " 'recently' 'recommend' 'recommended' 'red' 'relationship' 'release'\n",
            " 'released' 'remains' 'remake' 'remember' 'rent' 'respect' 'rest' 'result'\n",
            " 'return' 'revenge' 'review' 'reviews' 'rich' 'richard' 'ridiculous'\n",
            " 'right' 'robert' 'rock' 'role' 'roles' 'romance' 'romantic' 'room' 'run'\n",
            " 'running' 'runs' 'sad' 'sadly' 'said' 'save' 'saw' 'say' 'saying' 'says'\n",
            " 'scary' 'scene' 'scenes' 'school' 'sci' 'science' 'score' 'screen'\n",
            " 'screenplay' 'script' 'season' 'second' 'secret' 'seeing' 'seen' 'sees'\n",
            " 'self' 'sense' 'sequel' 'sequence' 'sequences' 'series' 'seriously' 'set'\n",
            " 'sets' 'setting' 'sex' 'sexual' 'shame' 'shoot' 'shooting' 'short' 'shot'\n",
            " 'shots' 'showed' 'showing' 'shown' 'shows' 'sick' 'silly' 'similar'\n",
            " 'simple' 'simply' 'singing' 'single' 'sister' 'sit' 'sitting' 'situation'\n",
            " 'situations' 'slightly' 'slow' 'small' 'social' 'society' 'solid'\n",
            " 'somewhat' 'son' 'song' 'songs' 'soon' 'sorry' 'sort' 'sound' 'sounds'\n",
            " 'soundtrack' 'space' 'speak' 'special' 'spend' 'spent' 'spirit'\n",
            " 'spoilers' 'stage' 'stand' 'standard' 'star' 'starring' 'stars' 'start'\n",
            " 'started' 'starts' 'state' 'stay' 'stick' 'stop' 'store' 'stories'\n",
            " 'story' 'storyline' 'straight' 'strange' 'street' 'strong' 'studio'\n",
            " 'stuff' 'stupid' 'style' 'subject' 'subtle' 'success' 'successful'\n",
            " 'suddenly' 'super' 'superb' 'supporting' 'supposed' 'sure' 'surprise'\n",
            " 'surprised' 'surprisingly' 'suspense' 'sweet' 'taken' 'takes' 'taking'\n",
            " 'tale' 'talent' 'talented' 'talk' 'talking' 'taste' 'team' 'television'\n",
            " 'tell' 'telling' 'tells' 'tension' 'terms' 'terrible' 'thank' 'thanks'\n",
            " 'theater' 'theme' 'thing' 'things' 'think' 'thinking' 'thinks' 'thought'\n",
            " 'thriller' 'time' 'times' 'title' 'today' 'told' 'tom' 'tone' 'took'\n",
            " 'total' 'totally' 'touch' 'touching' 'tough' 'town' 'trash' 'tried'\n",
            " 'tries' 'trip' 'trouble' 'true' 'truly' 'truth' 'try' 'trying' 'turn'\n",
            " 'turned' 'turns' 'tv' 'twist' 'twists' 'type' 'typical' 'ultimately'\n",
            " 'unbelievable' 'understand' 'unfortunately' 'unique' 'unless' 'unlike'\n",
            " 'use' 'used' 'uses' 'using' 'usual' 'usually' 'utterly' 'value' 'values'\n",
            " 'various' 've' 'version' 'video' 'view' 'viewer' 'viewers' 'viewing'\n",
            " 'villain' 'violence' 'violent' 'visual' 'voice' 'wait' 'waiting' 'walk'\n",
            " 'want' 'wanted' 'wants' 'war' 'wasn' 'waste' 'wasted' 'watch' 'watched'\n",
            " 'watching' 'water' 'way' 'ways' 'weak' 'week' 'weird' 'went' 'weren'\n",
            " 'western' 'white' 'wife' 'william' 'win' 'wish' 'woman' 'women' 'won'\n",
            " 'wonder' 'wonderful' 'word' 'words' 'work' 'worked' 'working' 'works'\n",
            " 'world' 'worse' 'worst' 'worth' 'wouldn' 'write' 'writer' 'writers'\n",
            " 'writing' 'written' 'wrong' 'wrote' 'yeah' 'year' 'years' 'yes' 'york'\n",
            " 'young' 'younger']\n"
          ]
        }
      ],
      "source": [
        "print(features.shape)\n",
        "print(vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_vqmxuNJKXs"
      },
      "source": [
        "Split the data into a training and validation (dev) set. We'll use the validation set to test our model. We'll use 75% of the data for training and 25% for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IgFqymeXcGzG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(features,train_data_labels,train_size=0.75,random_state=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz4X0a8sVEva"
      },
      "source": [
        "We will use Multinomial Naive Bayes to do the classification. Create the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Yn-H8cvpZMr9"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model = MultinomialNB()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHVdauzFJSWY"
      },
      "source": [
        "Train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TFPY4JrcZkFZ"
      },
      "outputs": [],
      "source": [
        "model = model.fit(X=X_train,y=y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQTvGAtwJWn3"
      },
      "source": [
        "Test the model on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xS22mi3sgr40"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HESEphJ1VvjQ"
      },
      "source": [
        "Now let's calculate the accuracy of the model's predictions on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak_-Ah-Ig1bz",
        "outputId": "57c14d29-c8ce-4384-dd26-d089592cc2ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.82784\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_val,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(model, open('ca337-nb1000-model.pkl', \"wb\"))\n",
        "pickle.dump(vectorizer,open('ca337-nb1000-features.pkl','wb'))"
      ],
      "metadata": {
        "id": "4QXnn-92gQVD"
      },
      "execution_count": 12,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}